{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metryki oparte na prawdopodobieństwie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve,roc_auc_score,precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puść ten kod, \n",
    "# jeżeli wywołujesz plik  w folderze rozwiąznaia, \n",
    "# a ramka danych znajduje się w folderze data\n",
    "import os \n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytanie zbioru danych\n",
    "df = pd.read_csv('data/credit_fraud_sample.csv')\n",
    "del df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pretrenuj model\n",
    "train_x, test_x, train_y, test_y = train_test_split(df.iloc[:,1:6],df['Class'], test_size=0.3, random_state=123)\n",
    "model = LogisticRegression().fit(train_x,train_y)\n",
    "train_pred = model.predict_proba(train_x)[:,1]\n",
    "test_pred = model.predict_proba(test_x)[:,1]\n",
    "df['predict_proba'] = model.predict_proba(df[model.feature_names_in_])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krzywa ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotwanie danych do wykresu\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(train_y,train_pred)\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(test_y, test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pole pod krzywą roc\n",
    "auc_train = round(roc_auc_score(train_y, train_pred),3)\n",
    "auc_test = round(roc_auc_score(test_y, test_pred),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres\n",
    "plt.plot(fpr_train,tpr_train,label = 'train')\n",
    "plt.plot(fpr_test,tpr_test,label = 'test')\n",
    "plt.plot(np.arange(0,1.1,0.1),np.arange(0,1.1,0.1),'--')\n",
    "plt.legend()\n",
    "plt.annotate(f'AUC train: {auc_train}',xy=[0.2,0.8])\n",
    "plt.annotate(f'AUC test: {auc_test}', xy=[0.2,0.75])\n",
    "plt.title('Krzywa ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Przygotowanie danych\n",
    "pr_train, recall_train, pr_thresholds_train = precision_recall_curve(train_y,train_pred)\n",
    "pr_test, recall_test, pr_thresholds_test = precision_recall_curve(test_y, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(recall_train, pr_train, label = 'train')\n",
    "plt.plot(recall_test, pr_test, label ='test')\n",
    "plt.legend()\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-S plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y train df\n",
    "train_pred_df = pd.DataFrame()\n",
    "train_pred_df['y_true'] = train_y\n",
    "train_pred_df['y_pred'] = train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y test df\n",
    "test_pred_df = pd.DataFrame()\n",
    "test_pred_df['y_true'] = test_y\n",
    "test_pred_df['y_pred'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=train_pred_df, x='y_pred', hue = 'y_true', fill =True)\n",
    "plt.title('Density of predicted probability by actual class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(data=test_pred_df, x='y_pred', hue = 'y_true', fill =True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inaczej\n",
    "test_0 = test_pred_df.loc[test_pred_df.y_true==0, 'y_pred']\n",
    "test_1 = test_pred_df.loc[test_pred_df.y_true==1, 'y_pred']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_stat, p_value = stats.ks_2samp(test_0, test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(test_0, bins=20, density = True, histtype='step',cumulative=True, label = 'Class 0')\n",
    "plt.hist(test_1, bins=20, density=True, histtype='step',cumulative=True, label = 'Class 1')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Skumulowane prawdopodobieństwo')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krzywa Gain i Lift\n",
    "Do wyznaczenia krzywych Gain oraz Lift potrzebujemy wyznaczyć wartości TPR i RPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lift_metrics(y_true, y_score):\n",
    "    cut_offs = np.arange(min(y_score),max(y_score),0.01)\n",
    "    rpps = []\n",
    "    lifts = []\n",
    "    tprs = []\n",
    "    for cut_off in cut_offs:\n",
    "        pred_class = (y_score>=cut_off).astype(int)\n",
    "        positive_values = np.sum(pred_class)\n",
    "        rpp = positive_values / len(pred_class)\n",
    "        tpr = np.sum((y_true ==  pred_class) & (y_true==1)) / np.sum(y_true)\n",
    "        lift = tpr/ rpp\n",
    "        rpps.append(rpp)\n",
    "        lifts.append(lift)\n",
    "        tprs.append(tpr)\n",
    "    return rpps, lifts, tprs, cut_offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyliczenie miar train\n",
    "rpps_train, lifts_train, tprs_train, cut_off_train = lift_metrics(train_pred_df['y_true'], train_pred_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpps_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lifts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wyliczenie miar test\n",
    "rpps_test, lifts_test, tprs_test, cut_off_test = lift_metrics(test_pred_df['y_true'], test_pred_df['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain perfect\n",
    "x = [0,test_pred_df['y_true'].sum() / len(test_pred_df['y_true']),1]\n",
    "y =[0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain \n",
    "plt.plot(rpps_train, tprs_train, label='train')\n",
    "plt.plot(rpps_test, tprs_test, label='test')\n",
    "plt.plot(rpps_train, rpps_train, label= 'random')\n",
    "plt.plot(x,y, color='red',label = 'perfect')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x,y do wykresu idealnego lift\n",
    "x_lift_p = [train_pred_df['y_true'].sum()/len(train_pred_df['y_true']),1]\n",
    "y_lift_p = [len(train_pred_df['y_true']) / train_pred_df['y_true'].sum(),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lift_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lift\n",
    "plt.plot(rpps_train, lifts_train,label = 'train')\n",
    "plt.plot(rpps_test, lifts_test, label = 'test')\n",
    "plt.plot(rpps_train, np.repeat(1,len(rpps_train)),label = 'random')\n",
    "plt.plot(x_lift_p,y_lift_p,'--', label = 'perfect')\n",
    "plt.legend()\n",
    "plt.title('Lift')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
